# Configuration Reference

Use this guide to configure the Clockify RAG stack across development laptops, CI, and production deployments. `clockify_rag/config.py` is the canonical source and every module reads from it, so updating the values there (via env vars or `.env`) immediately affects the CLI, API, and scripts. The system reads configuration in the following order (highest priority first):

1. Environment variables (`RAG_*`, `CLOCKIFY_*`, etc.)
2. `.env` file in the repository root (load with `python-dotenv` or `make dev`)
3. Hard-coded defaults in `clockify_rag.config`

> **Tip:** Legacy env names (`OLLAMA_URL`, `GEN_MODEL`, `EMB_MODEL`) are still honored, but the new `RAG_*` namespace is the supported path going forward.

## Core Connectivity

| Variable | Default | Description |
|----------|---------|-------------|
| `RAG_OLLAMA_URL` | `http://10.127.0.192:11434` | Base URL of the Ollama-compatible LLM host. Override with the local fallback (`http://127.0.0.1:11434`) when running Ollama on your laptop. |
| `RAG_CHAT_MODEL` | `qwen2.5:32b` | Primary generation model used for chat/ask flows. |
| `RAG_EMBED_MODEL` | `nomic-embed-text:latest` | Embedding model served by Ollama when `EMB_BACKEND=ollama`. |
| `EMB_BACKEND` | `local` | `local` uses SentenceTransformers; `ollama` sends embedding requests to `RAG_OLLAMA_URL`. |
| `RAG_LLM_CLIENT` | *(unset → real Ollama)* | Set to `mock` (or `test`) to force the deterministic offline client. Leaving it empty hits the configured Ollama host. |

## Retrieval & Prompting

| Variable | Default | Description |
|----------|---------|-------------|
| `DEFAULT_TOP_K` | `15` | Dense/BM25 candidates to fetch before filtering. |
| `DEFAULT_PACK_TOP` | `8` | Snippets to include in the prompt. |
| `DEFAULT_THRESHOLD` | `0.25` | Minimum hybrid score required for inclusion. |
| `DEFAULT_NUM_CTX` | `32768` | Context window passed to the LLM (`min(num_ctx, CTX_BUDGET * 1.0)` is used during packing). |
| `DEFAULT_NUM_PREDICT` | `512` | Maximum tokens generated by the LLM before truncation. |
| `DEFAULT_RETRIES` | `2` | Automatic retries for transient Ollama errors (chat + embeddings). |
| `CTX_BUDGET` | `12000` | Token budget reserved for snippets in the final prompt. |
| `ALPHA` | `0.5` | Blend factor for hybrid scoring (`alpha * BM25 + (1-alpha) * dense`). |
| `MMR_LAMBDA` | `0.75` | Balance between relevance and diversity during MMR selection. |
| `USE_INTENT_CLASSIFICATION` | `1` | Enable intent-aware dynamic alpha selection (set `0` to disable). |
| `MAX_QUERY_LENGTH` | `1000000` | Hard ceiling on sanitized query length (guards against DoS). |

## Timeouts & Performance

| Variable | Default | Description |
|----------|---------|-------------|
| `CHAT_CONNECT_TIMEOUT` | `3.0` | Connect timeout (seconds) for chat/generation calls. |
| `CHAT_READ_TIMEOUT` | `120.0` | Read timeout (seconds) for chat/generation calls. |
| `EMB_CONNECT_TIMEOUT` | `3.0` | Connect timeout for embedding calls. |
| `EMB_READ_TIMEOUT` | `60.0` | Read timeout for embedding calls. |
| `RERANK_READ_TIMEOUT` | `180.0` | Read timeout for optional rerank passes. |
| `EMB_MAX_WORKERS` | `8` | Parallel workers when calling Ollama embeddings. |
| `EMB_BATCH_SIZE` | `32` | Batch size per worker. |

## Indexing, Chunking, and ANN

| Variable | Default | Description |
|----------|---------|-------------|
| `CHUNK_CHARS` | `1600` | Target characters per chunk (ingestion). |
| `CHUNK_OVERLAP` | `200` | Character overlap between adjacent chunks. |
| `ANN` | `faiss` | ANN backend (`faiss` or `none`). |
| `ANN_NLIST` / `ANN_NPROBE` | `64` / `16` | FAISS IVF parameters for index quality vs. latency. |
| `FAISS_CANDIDATE_MULTIPLIER` | `3` | Retrieve `top_k * multiplier` dense results before reranking. |
| `ANN_CANDIDATE_MIN` | `200` | Minimum dense candidates even when `top_k` is tiny. |

## Logging & Compliance

| Variable | Default | Description |
|----------|---------|-------------|
| `RAG_LOG_FILE` | `rag_queries.jsonl` | Rolling JSONL log for chat/query traffic. |
| `RAG_LOG_INCLUDE_ANSWER` | `1` | Include answer text in logs (`0` redacts the answer body). |
| `RAG_LOG_INCLUDE_CHUNKS` | `0` | Include chunk bodies in logs (default redacts for privacy). |
| `RAG_LOG_ANSWER_PLACEHOLDER` | `[REDACTED]` | Replacement text when answers are redacted. |
| `RAG_STRICT_CITATIONS` | `0` | When `1`, the system refuses to answer without citations. |

## Cache, Rate Limits, and Query Expansions

| Variable | Default | Description |
|----------|---------|-------------|
| `CACHE_MAXSIZE` | `100` | LRU query cache size. |
| `CACHE_TTL` | `3600` | Cache entry TTL (seconds). |
| `RATE_LIMIT_REQUESTS` | `10` | Requests per rate-limit window (exposed for API compatibility). |
| `RATE_LIMIT_WINDOW` | `60` | Rate-limit window (seconds). |
| `CLOCKIFY_QUERY_EXPANSIONS` | *(bundled config/query_expansions.json)* | Override path for query expansion JSON; leave unset to use the repository default. |
| `MAX_QUERY_EXPANSION_FILE_SIZE` | `10_485_760` | Max bytes accepted for the expansion file (10 MB). |
| `FAQ_CACHE_ENABLED` | `0` | Enables the optional precomputed FAQ cache. |
| `FAQ_CACHE_PATH` | `faq_cache.json` | Location of the FAQ cache file when enabled. |

## API & Access Control

| Variable | Default | Description |
|----------|---------|-------------|
| `API_AUTH_MODE` | `none` | Set to `api_key` to require shared-secret auth on the FastAPI layer. |
| `API_ALLOWED_KEYS` | *(empty)* | Comma-separated list of API keys allowed when `API_AUTH_MODE=api_key`. |
| `API_KEY_HEADER` | `x-api-key` | HTTP header checked when API key auth is enabled. |

## Operational Toggles & Networking

| Variable | Default | Description |
|----------|---------|-------------|
| `WARMUP` | `1` | Preload FAISS/LLM on startup (set `0` for ultra-fast cold starts). |
| `NLTK_AUTO_DOWNLOAD` | `1` | Automatically fetch required NLTK assets during setup. |
| `BUILD_LOCK_TTL_SEC` | `900` | TTL for `.build.lock` to prevent overlapping ingests. |
| `ALLOW_PROXIES` | `0` | When `1`, propagate `HTTP(S)_PROXY` through `requests.Session.trust_env`. |
| `HTTP_PROXY` / `HTTPS_PROXY` | *(empty)* | Proxy URLs honored only when `ALLOW_PROXIES=1`. |

## Using `.env`

1. Copy `.env.example` to `.env`.
2. Adjust the values for your environment (VPN vs. local, timeouts, etc.).
3. Source the file (`set -a; source .env; set +a`) or rely on tooling that loads it automatically (`uvicorn`, `make dev`, etc.).

Example `.env` snippet for local development:

```bash
RAG_OLLAMA_URL=http://127.0.0.1:11434
RAG_CHAT_MODEL=qwen2.5:32b
RAG_EMBED_MODEL=nomic-embed-text:latest
EMB_BACKEND=local
DEFAULT_TOP_K=12
DEFAULT_PACK_TOP=6
```

Example for production on the VPN-hosted Ollama:

```bash
RAG_OLLAMA_URL=http://10.127.0.192:11434
RAG_CHAT_MODEL=qwen2.5:32b
RAG_EMBED_MODEL=nomic-embed-text:latest
EMB_BACKEND=ollama
CHAT_READ_TIMEOUT=300
EMB_READ_TIMEOUT=180
DEFAULT_RETRIES=4
```

## Validating Configuration

Run any of the following commands to ensure the config is wired correctly:

- `ragctl doctor --json` – dumps resolved config, index status, and Ollama connectivity.
- `python3 clockify_support_cli_final.py --selftest` – legacy self-test that reaches the configured endpoint.
- `python3 -m clockify_rag.api` – starts the FastAPI server and logs config banner + health checks.

If something looks off, check:

1. The resolved values in `clockify_rag/config.py` (`RAG_*` constants printed at startup).
2. That `.env` is being loaded (e.g., `pip install python-dotenv` and use `dotenv run`).
3. Whether the VPN route to `10.127.0.192:11434` is active (try `curl $RAG_OLLAMA_URL/api/tags`).

Document any environment-specific overrides (e.g., staging vs. prod) in `docs/DEPLOYMENT.md` so ops can reproduce the setup quickly.
